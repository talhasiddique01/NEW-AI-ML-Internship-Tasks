{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c80010-ca11-4518-b457-76742bdb53b6",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries\n",
    "\n",
    "\n",
    "pandas / numpy → handling dataset\n",
    "\n",
    "train_test_split → splitting data\n",
    "\n",
    "ColumnTransformer / Pipeline → preprocessing & pipeline\n",
    "\n",
    "LogisticRegression / RandomForestClassifier → ML models\n",
    "\n",
    "GridSearchCV → hyperparameter tuning\n",
    "\n",
    "joblib → export & reuse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6563fcd-33c6-4bcf-8da1-c0837842c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML utilities\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Save/load model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde0a32-9f23-4d90-993e-0b4822419b3e",
   "metadata": {},
   "source": [
    "# Cell 2: Load Dataset\n",
    "\n",
    "Reads CSV into a DataFrame\n",
    "\n",
    "df.head() shows first 5 rows\n",
    "\n",
    "Expected Output: Table with columns like customerID, gender, tenure, TotalCharges, Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36de7b2c-4220-44b4-93dd-0762a586dca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Telco Churn dataset\n",
    "\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10d3e4-e994-40fe-a175-98186886690f",
   "metadata": {},
   "source": [
    "# Cell 3: Data Set \n",
    "# 1. df.shape\n",
    "\n",
    "df is your pandas DataFrame containing the dataset.\n",
    "\n",
    ".shape returns a tuple (number_of_rows, number_of_columns).\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape) will show something like:\n",
    "\n",
    "Dataset Shape: (7043, 21)\n",
    "\n",
    "# 2. df.info()\n",
    "\n",
    "df.info() prints a summary of the DataFrame.\n",
    "\n",
    "Output includes:\n",
    "\n",
    "Number of rows\n",
    "\n",
    "Column names\n",
    "\n",
    "Non-null counts (helps check for missing values)\n",
    "\n",
    "Data type of each column (int64, float64, object)\n",
    "\n",
    "# 3. Outcome\n",
    "7043 rows → 7043 customers\n",
    "\n",
    "21 columns → features + target (Churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d17ce06-4ae7-4237-9531-f19fa719454d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (7043, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2943d4-9b96-499d-9ac0-b6cd79ce3fb4",
   "metadata": {},
   "source": [
    "# Cell 4: Data Cleaning & Target Encoding\n",
    "\n",
    "# 1.d.to_numeric(..., errors=\"coerce\")\n",
    "\n",
    "Converts TotalCharges from object → float\n",
    "\n",
    "Invalid entries become NaN\n",
    "\n",
    "# 2.df.dropna(inplace=True)\n",
    "\n",
    "Removes rows with NaN in TotalCharges\n",
    "\n",
    "Ensures all features are numeric/categorical\n",
    "\n",
    "# 3.Target Encoding\n",
    "\n",
    "Churn: Yes → 1 (customer left)\n",
    "\n",
    "No → 0 (customer stayed)\n",
    "\n",
    "# 4.Drop ID column\n",
    "\n",
    "customerID is unique → irrelevant for prediction\n",
    "\n",
    "# 5.Check dataset\n",
    "\n",
    ".shape → rows & columns after cleaning\n",
    "\n",
    ".info() → confirms data types & no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87a7f26a-24b7-4d84-876e-e6657689c8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Shape: (7032, 20)\n"
     ]
    }
   ],
   "source": [
    "# Convert TotalCharges to numeric\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert target to binary\n",
    "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Drop customerID\n",
    "df.drop(\"customerID\", axis=1, inplace=True)\n",
    "\n",
    "print(\"Cleaned Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865427ff-4be2-4e73-b39c-69d22c218e0a",
   "metadata": {},
   "source": [
    "# Cell 5: Features & Target Split\n",
    "# 1. X = df.drop(\"Churn\", axis=1)\n",
    "\n",
    "Drops the target column Churn from the DataFrame\n",
    "\n",
    "X contains all input features the model will use to predict churn\n",
    "\n",
    "# 2. y = df[\"Churn\"]\n",
    "\n",
    "Extracts the target variable\n",
    "\n",
    "y will be 0 or 1 (encoded in the previous cell)\n",
    "\n",
    "# 3. print(X.shape) & print(y.shape)\n",
    "\n",
    "Checks the number of rows and columns\n",
    "\n",
    "Confirms that feature matrix and target vector match in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "688e54fe-535c-46f2-9512-979c552bbab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7032, 19)\n",
      "y shape: (7032,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ad2a9-9e97-45f7-a7bd-26f527228ab1",
   "metadata": {},
   "source": [
    "# Cell 6: Train-Test Split\n",
    "\n",
    "# train_test_split(...)\n",
    "\n",
    "Splits your dataset into training and testing sets.\n",
    "\n",
    "Training set → used to train the model\n",
    "\n",
    "Testing set → used to evaluate the model\n",
    "\n",
    "# Parameters explained:\n",
    "\n",
    "X, y → features and target\n",
    "\n",
    "test_size=0.2 → 20% of data for testing, 80% for training\n",
    "\n",
    "random_state=42 → ensures reproducibility (same split every time)\n",
    "\n",
    "stratify=y → maintains the same proportion of churn (1) and non-churn (0) in both sets\n",
    "\n",
    "# X_train.shape[0] & X_test.shape[0]\n",
    "\n",
    "Prints number of samples in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55f1371a-f792-4fb9-88bb-932dcb2e0ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5625\n",
      "Testing samples: 1407\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5339b98-9a92-4a01-9c5a-280a3a090e3e",
   "metadata": {},
   "source": [
    "# Cell 7: Preprocessing Pipeline\n",
    "#  Numeric Transformer\n",
    "1. Pipeline: a sequence of steps; here, only scaling.\n",
    "\n",
    "2. StandardScaler:  \n",
    "    Transforms each numeric feature: (value - mean) / std\n",
    "\n",
    "    Result: mean = 0, standard deviation = 1\n",
    "\n",
    "Prevents numeric features with large values from dominating smaller ones\n",
    "\n",
    "# Create numeric transformer pipeline\n",
    "Scales numeric features → zero mean, unit variance\n",
    "\n",
    "Improves the performance of models like Logistic Regression\n",
    "\n",
    "# Create categorical transformer pipeline\n",
    "Converts categorical values to binary columns (0/1)\n",
    "\n",
    "handle_unknown=\"ignore\" → prevents errors if unseen categories appear in test data\n",
    "\n",
    "# Combinining numeric and categorical transformers using ColumnTransformer\n",
    "Applies numeric transformation to numeric features\n",
    "\n",
    "Applies categorical transformation to categorical features\n",
    "\n",
    "Returns a single transformed feature array ready for ML\n",
    "\n",
    "# Confirmation\n",
    "confirms the preprocessing pipeline is successfully created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "492d4353-0812-47c3-a11f-93452f3dc7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline ready\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f8eb9-d650-47fa-bbdc-c5d9d198e496",
   "metadata": {},
   "source": [
    "# Cell 8: Logistic Regression Pipeline\n",
    "\n",
    "# Purpose:\n",
    "\n",
    "Combines preprocessing and Logistic Regression into one unified pipeline.\n",
    "\n",
    "Makes the workflow clean, reusable, and production-ready.\n",
    "\n",
    "# Pipeline Steps\n",
    "\n",
    "1. \"preprocessor\" → the ColumnTransformer from Cell 7\n",
    "\n",
    "    Scales numeric features\n",
    "\n",
    "     One-hot encodes categorical features\n",
    "\n",
    "2. \"classifier\" → Logistic Regression model\n",
    "\n",
    "    max_iter=1000 ensures the solver has enough iterations to converge\n",
    "\n",
    "# Why use a pipeline?\n",
    "\n",
    "   Automatically applies preprocessing during training and testing\n",
    "\n",
    "   Prevents data leakage (test data must be transformed the same way as training data)\n",
    "\n",
    "   Allows hyperparameter tuning with GridSearchCV seamlessly\n",
    "\n",
    "   Easy to save and reuse with joblib\n",
    "\n",
    "# print(log_pipeline)\n",
    "\n",
    "Shows both preprocessing and model steps\n",
    "\n",
    "Confirms pipeline is ready for training or GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea92e010-733e-4ee7-993f-d968f61db7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges'], dtype='object')),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('encoder',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
      "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
      "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
      "       'PaperlessBilling', 'PaymentMethod'],\n",
      "      dtype='object'))])),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n"
     ]
    }
   ],
   "source": [
    "log_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "print(log_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b44df-6df1-4ddc-9346-e05b47d72bb6",
   "metadata": {},
   "source": [
    "# Cell 9: Hyperparameter Tuning for Logistic Regression\n",
    "# Define hyperparameters to tune\n",
    "  classifier__C → C parameter of Logistic Regression\n",
    "\n",
    "    Controls regularization strength (C inversely proportional to regularization)\n",
    "\n",
    "    Smaller C → stronger regularization → simpler model\n",
    "\n",
    "  The classifier__ prefix is needed because the Logistic Regression is inside the pipeline under the step named \"classifier\"\n",
    "# Set up GridSearchCV\n",
    "  log_pipeline → pipeline with preprocessing + Logistic Regression\n",
    "\n",
    "  log_params → hyperparameters to test\n",
    "\n",
    "  cv=5 → 5-fold cross-validation\n",
    "\n",
    "  Splits training data into 5 parts, trains on 4, validates on 1, repeats\n",
    "\n",
    "  scoring=\"f1\" → uses F1 score to evaluate model\n",
    "\n",
    "  Good for imbalanced datasets like churn (Churn = 1 is a minority)\n",
    "\n",
    "  n_jobs=-1 → uses all CPU cores for faster computation\n",
    "# Train and search best parameters\n",
    "   Fits the pipeline with all parameter combinations using cross-validation\n",
    "   \n",
    "   Finds the best C value based on highest F1 score\n",
    "# View results\n",
    "  best_params_ → the C value that performed best\n",
    "\n",
    "  best_score_ → cross-validated F1 score for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6faa063b-52ee-4bef-aba8-2f7856f901f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR Params: {'classifier__C': 10}\n",
      "Best LR F1 Score: 0.596454909838984\n"
     ]
    }
   ],
   "source": [
    "log_params = {\n",
    "    \"classifier__C\": [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "log_grid = GridSearchCV(\n",
    "    log_pipeline,\n",
    "    log_params,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "log_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LR Params:\", log_grid.best_params_)\n",
    "print(\"Best LR F1 Score:\", log_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5de70-d220-4b32-8139-a6e04466aafa",
   "metadata": {},
   "source": [
    "# Cell 10: Random Forest Pipeline\n",
    "# Purpose\n",
    "\n",
    "  Combines the preprocessing pipeline with a Random Forest classifier\n",
    "\n",
    "  Makes the workflow clean, reusable, and ready for training/testing\n",
    "\n",
    "# Pipeline Steps\n",
    "\"preprocessor\" → ColumnTransformer from Cell 7\n",
    "\n",
    "    Scales numeric features\n",
    "\n",
    "    One-hot encodes categorical features\n",
    "\n",
    "\"classifier\" → RandomForestClassifier\n",
    "\n",
    "    random_state=42 ensures reproducibility of results\n",
    " \n",
    "    Random Forest is an ensemble of decision trees, robust to non-linear relationships and handles categorical data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3706bd74-a3c8-4bed-94dd-b292c5771a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0277ac-02f8-4489-bd5e-fa5861239150",
   "metadata": {},
   "source": [
    "# Cell 11: Random Forest GridSearchCV\n",
    "# Purpose:\n",
    "Tune Random Forest hyperparameters (n_estimators, max_depth) using GridSearchCV.\n",
    "\n",
    "# Pipeline:\n",
    "    Uses rf_pipeline (preprocessing + Random Forest).\n",
    "\n",
    "# Cross-validation: \n",
    "    cv=5 ensures robust evaluation.\n",
    "\n",
    "# Scoring: \n",
    "    F1 score, suitable for imbalanced churn data.\n",
    "\n",
    "# Fit: \n",
    "    Trains all parameter combinations and finds best params.\n",
    "\n",
    "# Output:\n",
    "\n",
    "  best_params_ → best n_estimators & max_depth\n",
    "\n",
    "  best_score_ → corresponding F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1df06c2-c10b-46dd-9270-b8ef166fc1f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "Best RF F1 Score: 0.5826828193237013\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    rf_params,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best RF Params:\", rf_grid.best_params_)\n",
    "print(\"Best RF F1 Score:\", rf_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac33c8-a96a-4207-9019-e431f6c8f4ac",
   "metadata": {},
   "source": [
    "# Cell 12: Evaluate Random Forest Model\n",
    "best_model → the trained Random Forest pipeline with best hyperparameters.\n",
    "\n",
    "y_pred → predictions on the test set.\n",
    "\n",
    "Evaluation metrics:\n",
    "\n",
    "Accuracy → overall correct predictions\n",
    "\n",
    "F1 Score → balance of precision & recall, important for churn\n",
    "\n",
    "classification_report → detailed precision, recall, F1 for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a61f7bac-227a-4990-b5eb-429ac3e86edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7910447761194029\n",
      "F1 Score: 0.5676470588235294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1033\n",
      "           1       0.63      0.52      0.57       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.73      0.70      0.71      1407\n",
      "weighted avg       0.78      0.79      0.78      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = rf_grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea361d28-1f10-475f-8625-2c2887fc9a83",
   "metadata": {},
   "source": [
    "# Cell 13: Save the Model\n",
    "1. joblib.dump()\n",
    "\n",
    "   Saves the entire trained pipeline (best_model) to a file\n",
    "\n",
    "   Includes preprocessing + trained Random Forest classifier\n",
    "\n",
    "   File name: \"churn_prediction_pipeline.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1a0cc13-f7a7-434c-a8e4-9989099d2cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_model, \"churn_prediction_pipeline.pkl\")\n",
    "print(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f70d5-fd11-4a2e-8742-4d715c6d5098",
   "metadata": {},
   "source": [
    "# Cell 14: Load & Test Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98e9e90f-b30c-49a5-80fb-56618fedd387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "First 20 predictions (0=No Churn, 1=Churn):\n",
      "[0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0] \n",
      "\n",
      "Accuracy: 0.79\n",
      "F1 Score: 0.57\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1033\n",
      "           1       0.63      0.52      0.57       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.73      0.70      0.71      1407\n",
      "weighted avg       0.78      0.79      0.78      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Step 1: Load the saved model\n",
    "model = joblib.load(\"churn_prediction_pipeline.pkl\")\n",
    "print(\"Model loaded successfully!\\n\")\n",
    "\n",
    "# Step 2: Make predictions on the test set\n",
    "# Make sure X_test and y_test are defined as in your training\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 3: Show first 20 predictions\n",
    "print(\"First 20 predictions (0=No Churn, 1=Churn):\")\n",
    "print(y_pred[:20], \"\\n\")\n",
    "\n",
    "# Step 4: Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (churn_env)",
   "language": "python",
   "name": "churn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
